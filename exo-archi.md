# Architecture ComplÃ¨te - Lecteur Musical Intelligent

## ğŸ¯ Vue d'ensemble

Application web de lecteur musical avec analyse multimodale en temps rÃ©el (vidÃ©o + audio) pour dÃ©tecter l'attention et l'engagement de l'utilisateur et adapter l'expÃ©rience d'Ã©coute.

---

## ğŸ“ Architecture Globale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FRONTEND (HTML/JS)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Lecteur    â”‚  â”‚   CamÃ©ra +   â”‚  â”‚    Widgets &    â”‚ â”‚
â”‚  â”‚   Audio     â”‚  â”‚   Micro      â”‚  â”‚    Analytics    â”‚ â”‚
â”‚  â”‚ (script.js) â”‚  â”‚ (WebSocket)  â”‚  â”‚  (widgets.js)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                 â”‚                   â”‚           â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                           â”‚                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    WebSocket/HTTP
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   BACKEND (Flask/Python)                   â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              main.py (Serveur Flask)               â”‚   â”‚
â”‚  â”‚  - Routes API REST                                 â”‚   â”‚
â”‚  â”‚  - WebSocket (Flask-SocketIO)                      â”‚   â”‚
â”‚  â”‚  - Gestion playlist                                â”‚   â”‚
â”‚  â”‚  - Analytics utilisateur                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚              â”‚              â”‚              â”‚               â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚    â”‚ AttentionDetectorâ”‚    â”‚    â”‚ MultimodalSystem   â”‚   â”‚
â”‚    â”‚ (attention_      â”‚â—„â”€â”€â”€â”¼â”€â”€â”€â”€â”¤ (multimodal_       â”‚   â”‚
â”‚    â”‚  system.py)      â”‚    â”‚    â”‚  system.py)        â”‚   â”‚
â”‚    â”‚                  â”‚    â”‚    â”‚                    â”‚   â”‚
â”‚    â”‚ - Score attentionâ”‚    â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚    â”‚ - Adaptations    â”‚    â”‚    â”‚ â”‚VideoAnalyzer  â”‚  â”‚   â”‚
â”‚    â”‚ - RÃ¨gles mÃ©tier  â”‚    â”‚    â”‚ â”‚ (OpenCV +     â”‚  â”‚   â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚ â”‚  Haar Cascade)â”‚  â”‚   â”‚
â”‚                            â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚                            â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚                            â”‚    â”‚ â”‚AudioAnalyzer  â”‚  â”‚   â”‚
â”‚                            â”‚    â”‚ â”‚ (NumPy +      â”‚  â”‚   â”‚
â”‚                            â”‚    â”‚ â”‚  Librosa opt.)â”‚  â”‚   â”‚
â”‚                            â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚                            â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚                            â”‚    â”‚ â”‚EmotionFusion  â”‚  â”‚   â”‚
â”‚                            â”‚    â”‚ â”‚ (Fusion des   â”‚  â”‚   â”‚
â”‚                            â”‚    â”‚ â”‚  signaux A/V) â”‚  â”‚   â”‚
â”‚                            â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚                            â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                            â”‚                             â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚                    â”‚  user_analyticsâ”‚                    â”‚
â”‚                    â”‚      .json      â”‚                    â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ Architecture par Couches

### 1ï¸âƒ£ **COUCHE PRÃ‰SENTATION (Frontend)**

#### **A. Interface Utilisateur (HTML/CSS)**
- **Fichier principal**: `templates/index.html`
- **Structure**:
  - Logo (haut gauche)
  - Lecteur audio central
  - Widgets latÃ©raux (camÃ©ra, analyses, chansons validÃ©es)
  - SÃ©lecteur de thÃ¨mes

#### **B. Styles**
- `style.css` : Styles principaux, layout grid
- `themes.css` : ThÃ¨mes dynamiques (neutral, energy, calm, focus, etc.)
- `theme-selector.css` : SÃ©lecteur de thÃ¨mes
- `widget.css` : Styles des widgets
- `analytics.css` : Styles des analytics
- `attention-adapter.css` : Indicateurs visuels d'attention

#### **C. Scripts JavaScript**

**Script principal** (`script.js`) :
```javascript
- ContrÃ´le lecteur audio (play/pause/next/prev)
- Gestion playlist locale
- Communication HTTP avec backend
- Mise Ã  jour UI en temps rÃ©el
- Gestion Ã©vÃ©nements utilisateur
```

**Theme Engine** (`theme-engine.js`) :
```javascript
- Application dynamique des thÃ¨mes
- Transitions fluides entre ambiances
- Adaptation selon Ã©motions dÃ©tectÃ©es
```

**Widgets Manager** (`widgets.js`) :
```javascript
- Gestion des widgets modulaires
- Panneaux d'information
- ContrÃ´les rapides (shuffle, repeat)
- Tooltips et effets visuels
```

**Attention Adapter** (`attention-adapter.js`) :
```javascript
- Monitoring de l'attention utilisateur cÃ´tÃ© client
- DÃ©tection d'inactivitÃ©
- Tracking visibilitÃ© onglet (Page Visibility API)
- Adaptations UI selon niveau d'attention
- Communication avec AttentionDetector backend
```

**Analytics** (`analytics.js`) :
```javascript
- Affichage des mÃ©triques utilisateur
- Graphiques d'engagement
- Historique des interactions
```

**Multimodal Capture** (`multimodal-capture.js`) :
```javascript
- Capture webcam (MediaStream API)
- Capture microphone
- Envoi frames vidÃ©o via WebSocket
- Envoi chunks audio via WebSocket
- Throttling pour optimiser la bande passante
```

---

### 2ï¸âƒ£ **COUCHE COMMUNICATION (WebSocket + REST)**

#### **WebSocket Events** (via Flask-SocketIO)

**Client â†’ Serveur** :
- `video_frame` : Frame webcam (base64)
- `audio_chunk` : Chunk audio microphone
- `track_interaction` : Interactions utilisateur (play, pause, skip, volume)

**Serveur â†’ Client** :
- `attention_update` : Mise Ã  jour score d'attention
- `theme_change` : Changement de thÃ¨me suggÃ©rÃ©
- `analysis_update` : DonnÃ©es d'analyse multimodale

#### **API REST** (Flask routes)

```python
GET  /                      # Page principale
GET  /api/playlist          # RÃ©cupÃ©rer la playlist
POST /api/upload            # Upload fichiers audio
POST /api/play/:index       # Jouer une chanson
POST /api/pause             # Mettre en pause
POST /api/next              # Chanson suivante
POST /api/previous          # Chanson prÃ©cÃ©dente
POST /api/volume            # Changer volume
POST /api/shuffle           # Toggle shuffle mode
POST /api/repeat            # Toggle repeat mode
GET  /api/get-modes         # RÃ©cupÃ©rer modes shuffle/repeat
GET  /api/analytics         # RÃ©cupÃ©rer analytics utilisateur
GET  /api/attention/state   # Ã‰tat du systÃ¨me d'attention
POST /api/attention/track   # Enregistrer interaction
```

---

### 3ï¸âƒ£ **COUCHE MÃ‰TIER (Backend Python)**

#### **A. Serveur Principal** (`main.py`)

**ResponsabilitÃ©s** :
- Serveur Flask + SocketIO
- Gestion des routes API REST
- Gestion de la playlist (liste, upload, ordre)
- Extraction mÃ©tadonnÃ©es audio (Mutagen)
- Orchestration des systÃ¨mes d'attention et multimodal
- Persistance analytics (`user_analytics.json`)
- Auto-skip basÃ© sur l'attention

**Variables globales** :
```python
playlist = []                    # Liste des chansons
current_index = 0                # Index chanson actuelle
is_playing = False               # Ã‰tat lecture
shuffle_mode, repeat_mode        # Modes lecture
attention_detector               # Instance AttentionDetector
multimodal_system                # Instance MultimodalSystem
user_analytics                   # Dict analytics utilisateur
```

**MÃ©canisme d'auto-skip** :
```python
- VÃ©rification pÃ©riodique du score d'attention
- Si score < MIN_ATTENTION_THRESHOLD (65) pendant X secondes
- Skip automatique vers chanson suivante
- Cooldown entre skips (10 secondes)
```

#### **B. SystÃ¨me d'Attention** (`attention_system.py`)

**Classe** : `AttentionDetector`

**Objectif** : Estimer le niveau d'attention de l'utilisateur sans IA, par rÃ¨gles comportementales.

**Ã‰tats d'attention** :
- `attentif` (100-80%)
- `semi-attentif` (79-60%)
- `peu-attentif` (59-40%)
- `pas-attentif` (<40%)

**Signaux analysÃ©s** :
```python
WEIGHTS = {
    'time_since_interaction': 40%,  # Temps sans interaction
    'skip_rate': 25%,               # FrÃ©quence de skips
    'manual_adjustments': 15%,      # Ajustements manuels (volume, seek)
    'pause_frequency': 10%,         # Pauses/reprises
    'tab_switches': 10%,            # Changements d'onglet
}
```

**Seuils de temps** :
```python
interaction_timeout: 3s      # Temps avant dÃ©crÃ©ment score
semi_attentive: 8s           # Passage semi-attentif
low_attention: 15s           # Passage peu-attentif
no_attention: 30s            # Passage pas-attentif
skip_burst_window: 20s       # FenÃªtre dÃ©tection skips rapides
```

**MÃ©thodes principales** :
```python
track_interaction(type, data)  # Enregistrer interaction
update_attention_level()       # Recalculer score attention
apply_adaptation()             # Appliquer adaptations
get_state()                    # Ã‰tat actuel
```

**Adaptations** :
- Ajustement volume automatique
- Suggestions de changement de playlist/style
- Modification intensitÃ© UI
- Skip automatique si dÃ©sengagement prolongÃ©

#### **C. SystÃ¨me Multimodal** (`multimodal_system.py`)

**Classe** : `MultimodalSystem`

**Objectif** : Fusionner analyses vidÃ©o et audio pour enrichir le score d'attention.

**Architecture multi-thread** :
```python
Thread 1: VideoAnalyzer      # Analyse frames webcam
Thread 2: AudioAnalyzer       # Analyse audio microphone
Thread 3: EmotionFusion       # Fusion des deux
```

**Queues de traitement** :
```python
video_queue = Queue(maxsize=10)
audio_queue = Queue(maxsize=10)
```

**Flux de donnÃ©es** :
```
WebSocket â†’ add_video_frame() â†’ video_queue â†’ VideoAnalyzer
WebSocket â†’ add_audio_chunk() â†’ audio_queue â†’ AudioAnalyzer
                                     â†“
                               EmotionFusion
                                     â†“
                          AttentionDetector.update()
```

---

### 4ï¸âƒ£ **COUCHE ANALYSE (Analyzers)**

#### **A. Video Analyzer** (`analyzers/video_analyzer.py`)

**Technologies** : OpenCV + Haar Cascades

**Analyses** :
1. **DÃ©tection visage** :
   - Haar Cascade frontal + profile
   - Validation par stabilitÃ© (historique frames)

2. **Pose de la tÃªte** (Head Pose Estimation) :
   ```python
   yaw   # Rotation gauche/droite (-90Â° Ã  +90Â°)
   pitch # Inclinaison haut/bas (-90Â° Ã  +90Â°)
   roll  # Rotation tÃªte sur Ã©paule
   ```
   - Calcul via position relative du visage
   - Lissage exponentiel (smoothing_factor=0.15)

3. **Expression faciale** :
   - DÃ©tection yeux (Haar Cascade)
   - DÃ©tection sourire (Haar Cascade)
   - Estimation Ã©motion : `happy`, `neutral`, `sad`, `surprised`
   - Confidence score

4. **Score d'engagement** :
   ```python
   Facteurs:
   - Position tÃªte (centrÃ© = mieux)
   - Orientation (face camÃ©ra = mieux)
   - Expression (sourire = bonus)
   - PrÃ©sence visage (absent = 0)
   ```

**Output** :
```python
{
    'face_detected': bool,
    'head_pose': {'pitch': float, 'yaw': float, 'roll': float},
    'engagement_score': int (0-100),
    'emotion_hint': str,
    'facial_expression': {
        'emotion': str,
        'confidence': float
    }
}
```

#### **B. Audio Analyzer** (`analyzers/audio_analyzer.py`)

**Technologies** : NumPy + Librosa (optionnel)

**Analyses** :
1. **Niveau d'Ã©nergie** (RMS - Root Mean Square) :
   ```python
   rms = sqrt(mean(audio_chunk^2))
   energy_level = min(100, int(rms * 1000))
   ```

2. **DÃ©tection de parole** :
   - Seuil d'Ã©nergie : 0.06
   - `speech_detected = True` si Ã©nergie > seuil

3. **Pitch estimation** (frÃ©quence vocale) :
   - Zero-crossing rate
   - Estimation frÃ©quence fondamentale

4. **Ã‰motion vocale** (si Librosa disponible) :
   - Analyse spectrale
   - Classification Ã©motion : `neutral`, `happy`, `sad`, `angry`

**Output** :
```python
{
    'speech_detected': bool,
    'energy_level': int (0-100),
    'pitch': float,
    'emotion_hint': str
}
```

#### **C. Emotion Fusion** (`analyzers/emotion_fusion.py`)

**Classe** : `EmotionFusion`

**Objectif** : Fusionner signaux vidÃ©o + audio pour score unifiÃ©.

**MÃ©thode** : `fuse_signals(video_state, audio_state)`

**Ã‰tapes** :
1. **Calcul score d'attention combinÃ©** :
   ```python
   video_weight = 0.6
   audio_weight = 0.4
   attention_score = (video.engagement * 0.6) + (audio.energy * 0.4)
   ```

2. **DÃ©termination Ã©motion dominante** :
   - PrioritÃ© : Expression faciale
   - Fallback : Ã‰motion vocale
   - Historique pour stabilitÃ©

3. **DÃ©tection de patterns** :
   ```python
   'engaged'      # Visage + parole actifs
   'passive'      # Visage prÃ©sent, pas de parole
   'listening'    # Ã‰coute passive
   'absent'       # Rien dÃ©tectÃ©
   'distracted'   # Mouvements erratiques
   ```

4. **Indicateurs persistants** :
   ```python
   movement_detected_once  # True si mouvement dÃ©tectÃ© au moins 1 fois
   speech_detected_once    # True si parole dÃ©tectÃ©e au moins 1 fois
   both_active             # True si les deux
   ```

**Output** :
```python
{
    'attention_score': int (0-100),
    'emotion': str,
    'pattern': str,
    'movement_detected': bool,
    'speech_detected': bool,
    'both_active': bool,
    'video': dict,
    'audio': dict
}
```

---

### 5ï¸âƒ£ **COUCHE DONNÃ‰ES**

#### **A. Fichiers audio** (`music_files/`)
- Stockage des fichiers audio uploadÃ©s
- Formats supportÃ©s : MP3, WAV, OGG, M4A, FLAC

#### **B. Analytics utilisateur** (`user_analytics.json`)

**Structure** :
```json
{
  "songs": {
    "song_id": {
      "title": str,
      "artist": str,
      "duration": float,
      "play_count": int,
      "skip_count": int,
      "completion_rate": float,
      "avg_volume": float,
      "last_played": timestamp,
      "total_listen_time": float,
      "attention_scores": [int],
      "avg_attention": float
    }
  },
  "listening_patterns": {
    "total_playtime": float,
    "total_sessions": int,
    "avg_session_duration": float,
    "skip_rate": float,
    "completion_rate": float
  },
  "preferences": {
    "favorite_songs": [str],
    "disliked_songs": [str],
    "most_played": [str]
  },
  "adaptive_settings": {
    "ui_complexity": str,
    "auto_skip_enabled": bool,
    "smart_shuffle_enabled": bool
  }
}
```

---

## ğŸ”„ Flux de DonnÃ©es Complets

### **Flux 1 : Lecture Audio**

```
1. User clique Play
   â†“
2. script.js â†’ POST /api/play/:index
   â†“
3. main.py met Ã  jour current_index, is_playing=True
   â†“
4. Retour donnÃ©es chanson (titre, artiste, URL)
   â†“
5. script.js charge audioElement.src et play()
   â†“
6. main.py track interaction 'play' â†’ AttentionDetector
   â†“
7. AttentionDetector met Ã  jour score d'attention
   â†“
8. Analytics mises Ã  jour (play_count++, last_played, etc.)
```

### **Flux 2 : Analyse Multimodale Temps RÃ©el**

```
1. User active camÃ©ra/micro (toggle)
   â†“
2. multimodal-capture.js dÃ©marre MediaStream
   â†“
3. Capture frames Ã  2 FPS via canvas
   â†“
4. Conversion base64 â†’ emit('video_frame')
   â†“
5. main.py @socketio.on('video_frame')
   â†“
6. multimodal_system.add_video_frame(frame)
   â†“
7. VideoAnalyzer.analyze_frame() [Thread 1]
   â”‚ - DÃ©tection visage (Haar)
   â”‚ - Estimation pose tÃªte
   â”‚ - Analyse expression
   â”‚ - Calcul engagement_score
   â†“
8. AudioAnalyzer.analyze_audio() [Thread 2]
   â”‚ - Calcul Ã©nergie (RMS)
   â”‚ - DÃ©tection parole
   â”‚ - Estimation pitch
   â†“
9. EmotionFusion.fuse_signals() [Thread 3]
   â”‚ - Fusion des signaux
   â”‚ - Calcul attention_score unifiÃ©
   â”‚ - DÃ©tection patterns
   â†“
10. AttentionDetector.update() (injection score multimodal)
   â†“
11. emit('attention_update', state) â†’ Client
   â†“
12. attention-adapter.js met Ã  jour UI
    - Indicateur visuel attention
    - Adaptation volume si nÃ©cessaire
    - Suggestion changement thÃ¨me
```

### **Flux 3 : Auto-Skip Intelligent**

```
1. AttentionDetector calcule score en continu
   â†“
2. Si score < 65 pendant X secondes
   â†“
3. main.py dÃ©clenche auto-skip
   â†“
4. POST /api/next (serveur lui-mÃªme)
   â†“
5. Passage Ã  chanson suivante
   â†“
6. Notification UI "ChangÃ© automatiquement (faible engagement)"
   â†“
7. Cooldown 10 secondes avant prochain auto-skip
   â†“
8. Analytics : skip_count++, reason='low_attention'
```

### **Flux 4 : Adaptation ThÃ¨me**

```
1. EmotionFusion dÃ©tecte Ã©motion dominante
   â†“
2. emit('theme_change', {emotion: 'happy'})
   â†“
3. theme-engine.js reÃ§oit suggestion
   â†“
4. Si variations automatiques activÃ©es
   â†“
5. Application thÃ¨me correspondant
   - happy â†’ theme-energy
   - calm â†’ theme-calm
   - sad â†’ theme-sunset
   â†“
6. Transitions CSS fluides (0.5s)
```

---

## ğŸ§© Technologies UtilisÃ©es

### **Backend**
- **Flask** : Framework web Python
- **Flask-SocketIO** : Communication temps rÃ©el (WebSocket)
- **Mutagen** : Extraction mÃ©tadonnÃ©es audio (MP3, ID3)
- **OpenCV** : Traitement d'image, dÃ©tection visages
- **NumPy** : Calculs numÃ©riques (audio, vidÃ©o)
- **Librosa** (optionnel) : Analyse audio avancÃ©e

### **Frontend**
- **Vanilla JavaScript** : Pas de framework lourd
- **Socket.IO Client** : WebSocket cÃ´tÃ© client
- **HTML5 Audio API** : Lecteur audio natif
- **MediaStream API** : Capture webcam/micro
- **Page Visibility API** : DÃ©tection onglet actif/inactif
- **Canvas API** : Traitement frames vidÃ©o

### **Analyse VidÃ©o**
- **Haar Cascades** (OpenCV) :
  - `haarcascade_frontalface_default.xml`
  - `haarcascade_profileface.xml`
  - `haarcascade_eye.xml`
  - `haarcascade_smile.xml`

---

## ğŸ¨ SystÃ¨me de ThÃ¨mes

**ThÃ¨mes disponibles** :
- `neutral` : Neutre, gris bleutÃ©
- `energy` : Ã‰nergique, orange vif
- `calm` : Calme, bleu doux
- `focus` : Focus, violet profond
- `sunset` : Coucher de soleil, rose/orange
- `midnight` : Minuit, bleu sombre
- `sunsetDark` : Sombre chaleureux, marron/orange
- `aurora` : Aurore, vert/bleu
- `lavender` : Lavande, violet clair
- `ocean` : OcÃ©an, bleu turquoise
- `fire` : Feu, rouge/orange

**Variables CSS dynamiques** :
```css
--bg-primary, --bg-secondary
--text-primary, --text-secondary
--accent-color, --accent-glow
--card-bg, --border-color
--shadow-color
```

**Transitions** : 0.5s ease

---

## ğŸ“Š Analytics & Adaptations

### **MÃ©triques Suivies**
1. **Par chanson** :
   - Nombre d'Ã©coutes
   - Taux de complÃ©tion
   - Skips
   - Volume moyen
   - Scores d'attention

2. **Globales** :
   - Temps d'Ã©coute total
   - Nombre de sessions
   - DurÃ©e moyenne session
   - Taux de skip global
   - Patterns temporels (heures d'Ã©coute prÃ©fÃ©rÃ©es)

### **Adaptations Automatiques**
1. **Volume** : Baisse progressive si dÃ©sengagement
2. **Skip automatique** : Si attention < 65 pendant X temps
3. **Suggestions playlist** : BasÃ©es sur historique
4. **ThÃ¨me** : AdaptÃ© Ã  l'Ã©motion dÃ©tectÃ©e
5. **UI** : ComplexitÃ© ajustÃ©e au niveau d'engagement

---

## ğŸš€ DÃ©marrage & Configuration

### **Installation**
```bash
pip install -r requirements.txt
```

### **DÃ©pendances principales**
```
Flask
Flask-SocketIO
mutagen
opencv-python
numpy
librosa (optionnel)
python-socketio
```

### **Lancement**
```bash
python main.py
```

Serveur dÃ©marre sur `http://127.0.0.1:5000`

---

## ğŸ” SÃ©curitÃ© & Performance

### **SÃ©curitÃ©**
- CORS activÃ© pour WebSocket
- Taille max upload : 50 MB
- Validation types fichiers
- Pas de stockage serveur permanent (sauf analytics)

### **Performance**
- Throttling capture vidÃ©o : 2 FPS
- Throttling capture audio : chunks 1024 samples
- Queue max size : 10 items (Ã©vite surcharge mÃ©moire)
- Multi-threading pour analyses (non-bloquant)
- Lissage exponentiel (Ã©vite valeurs erratiques)
- Skip frame si analyse trop lente

### **Optimisations**
- PrÃ©chargement audio (`preload='auto'`)
- Canvas offscreen pour traitement vidÃ©o
- Historiques limitÃ©s (max 10 items)
- Cooldowns sur actions frÃ©quentes (auto-skip)

---

## ğŸ¯ Points Forts de l'Architecture

1. **SÃ©paration des prÃ©occupations** :
   - Frontend/Backend bien sÃ©parÃ©s
   - Analyseurs modulaires indÃ©pendants
   - SystÃ¨me d'attention dÃ©couplÃ© du multimodal

2. **ExtensibilitÃ©** :
   - Ajout facile de nouveaux analyseurs
   - Nouveaux patterns d'engagement
   - Nouveaux thÃ¨mes

3. **Temps rÃ©el** :
   - WebSocket pour communication bidirectionnelle
   - Multi-threading pour analyses parallÃ¨les
   - Mise Ã  jour UI instantanÃ©e

4. **RÃ©silience** :
   - Fallbacks si librosa absent
   - Gestion erreurs capture webcam/micro
   - Mode dÃ©gradÃ© si analyses Ã©chouent

5. **AdaptabilitÃ©** :
   - RÃ¨gles mÃ©tier modifiables facilement
   - Seuils configurables
   - Modes d'adaptation dÃ©sactivables

---

## ğŸ“ AmÃ©liorations Futures Possibles

1. **IA/ML** :
   - ModÃ¨les deep learning pour Ã©motions (FER+, AffectNet)
   - Reconnaissance parole (Speech-to-Text)
   - PrÃ©diction prÃ©fÃ©rences musicales

2. **FonctionnalitÃ©s** :
   - Playlists intelligentes
   - Recommandations collaboratives
   - Mode multi-utilisateurs
   - Synchronisation multi-devices

3. **Analyses** :
   - DÃ©tection fatigue (bÃ¢illements, clignements)
   - Tracking regard (eye gaze)
   - Analyse posture corporelle (pose estimation)
   - BiomÃ©trie (heart rate via webcam)

4. **Performance** :
   - WebAssembly pour analyses cÃ´tÃ© client
   - Web Workers pour traitement parallÃ¨le
   - GPU acceleration (WebGL)

---

## ğŸ“š RÃ©fÃ©rences

- **OpenCV Haar Cascades** : https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html
- **Flask-SocketIO** : https://flask-socketio.readthedocs.io/
- **MediaStream API** : https://developer.mozilla.org/en-US/docs/Web/API/MediaStream_API
- **Page Visibility API** : https://developer.mozilla.org/en-US/docs/Web/API/Page_Visibility_API
- **Mutagen** : https://mutagen.readthedocs.io/

---

**Version** : 1.0  
**Date** : Janvier 2026  
**Auteur** : Regis
